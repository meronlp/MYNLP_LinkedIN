{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doc2vec: How To Prep Document Vectors For Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Our Own Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data, clean it, split it into train/test, and then train a doc2vec model\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "messages = pd.read_csv('./data/spam.csv', encoding='latin-1')\n",
    "messages = messages.drop(labels = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis = 1)\n",
    "messages.columns = [\"label\", \"text\"]\n",
    "messages['text_clean'] = messages['text'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages['text_clean'],\n",
    "                                                    messages['label'], test_size=0.2)\n",
    "\n",
    "tagged_docs_tr = [gensim.models.doc2vec.TaggedDocument(v, [i]) for i, v in enumerate(X_train)]\n",
    "\n",
    "d2v_model = gensim.models.Doc2Vec(tagged_docs_tr,\n",
    "                                  vector_size=50,\n",
    "                                  window=2,\n",
    "                                  min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0160803 ,  0.01025523,  0.03182423,  0.02497851,  0.00465351,\n",
       "        0.00447948,  0.01410904, -0.03273206, -0.00268471, -0.006954  ,\n",
       "        0.00785535,  0.00921986,  0.01115193,  0.0028922 , -0.01799711,\n",
       "        0.01185948, -0.00047327, -0.03291325, -0.00081088, -0.00520088,\n",
       "        0.03184735, -0.01408158,  0.00842579,  0.00569051,  0.00489169,\n",
       "       -0.00069536,  0.01676262,  0.01821817, -0.02275796, -0.00573135,\n",
       "       -0.01581258,  0.01050034,  0.02330843,  0.01478808, -0.01017254,\n",
       "       -0.00776446,  0.00073255,  0.00584688,  0.01352263, -0.01278319,\n",
       "        0.03053902,  0.02606562,  0.01142512, -0.00947258, -0.00339353,\n",
       "       -0.00115252, -0.00766568,  0.00707489,  0.00546808,  0.00156479],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does a document vector look like again?\n",
    "d2v_model.infer_vector(['convert', 'words', 'to', 'vectors'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we prepare these vectors to be used in a machine learning model?\n",
    "vectors = [[d2v_model.infer_vector(words)] for words in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.03175561,  0.01439424,  0.04863995,  0.04242408,  0.00370294,\n",
       "         0.01031234,  0.01245122, -0.05891113, -0.01267266, -0.01531839,\n",
       "         0.00199126,  0.02146759,  0.03133297,  0.01253926, -0.03108902,\n",
       "         0.02072878,  0.01061508, -0.05465336,  0.00413387, -0.00840401,\n",
       "         0.0490956 , -0.03260579,  0.01115101,  0.02657761, -0.00176361,\n",
       "        -0.00407269,  0.0336531 ,  0.05472916, -0.04284498,  0.00895467,\n",
       "        -0.03518188,  0.01422446,  0.03778114,  0.02076449, -0.02059564,\n",
       "         0.00427171, -0.01031834,  0.01640993,  0.01220672, -0.02292535,\n",
       "         0.05847409,  0.07545223,  0.01042801, -0.00586517,  0.01101934,\n",
       "        -0.00112158, -0.00489529, -0.00517681,  0.00772747,  0.01563663],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.05390054,  0.04178806,  0.0731267 ,  0.0703095 , -0.00513255,\n",
       "         0.01171278,  0.0126497 , -0.08593671, -0.00895066, -0.02875345,\n",
       "         0.01776839,  0.01333664,  0.04228383,  0.01407511, -0.03641236,\n",
       "         0.02997456,  0.00567681, -0.0907494 , -0.00569733,  0.00560542,\n",
       "         0.07772337, -0.04426915,  0.01667151,  0.0448153 ,  0.00234522,\n",
       "        -0.02207201,  0.04176671,  0.06389876, -0.06267015,  0.01604028,\n",
       "        -0.03875209,  0.0245656 ,  0.04605745,  0.02375552, -0.02915484,\n",
       "         0.00389715, -0.0092312 ,  0.01014214,  0.01849409, -0.04075533,\n",
       "         0.07164147,  0.10245278,  0.02752741, -0.02072025,  0.00768327,\n",
       "        -0.00224492, -0.00579937,  0.00574254,  0.02090523,  0.02146467],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
